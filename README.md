# GALAXY: Large-Scale Open-Domain Dataset for Multimodal Learning
In this repository, we introduce **GALAXY**, a large-scale, open-domain dataset designed for multimodal learning, containing 8,270 hours of videos, speech, and transcriptions across 16 diverse domains.

## Introduction
Humans inherently rely on multimodal information -- vision, audio, and text -- to solve problems collaboratively. In a similar manner, artificial intelligence systems require cross-modal or multimodal information to effectively perform tasks. Given that the performance of multimodal models is fundamentally constrained by the quality of the data and annotations used for training, there is a critical need for a high-quality, large-scale dataset containing visual, speech, and text modalities to facilitate the advancement of multimodal model development.

GALAXY is a large-scale, open-domain multimodal dataset encompassing vision, speech, and text modalities. GALAXY is designed to meet the following key characteristics:
* **Multimodal.** GALAXY consists of videos paired with speech and transcriptions. The naturally paired multimodal information in GALAXY makes it an ideal resource for advancing multimodal development.
* **Large-scale.** The GALAXY dataset contains 8,270 hours of videos with more than 11M utterances, making it appropriate for both pretraining and downstream tasks.
* **Open-domain.** GALAXY covers a wide range of video domains from the real world, providing significant diversity to encourage models to learn from diverse scenarios.
* **High-quality.** GALAXY applies strict filtering to ensure a high correlation between speech and text, retaining only videos where the speech and text content align. This process minimizes the impact of data noise on model training. 


## Download Dataset

## Prepare Dataset

## Train Multimodal Speech Recognition Models

## Paper
Please cite the following paper in all academic work that uses this dataset:

`
`

## GALAXY License
Unless noted otherwise, we are providing the contents of this repository under the [Creative Commons BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/) (Attribution-Share-Alike) License (for data-like content).
